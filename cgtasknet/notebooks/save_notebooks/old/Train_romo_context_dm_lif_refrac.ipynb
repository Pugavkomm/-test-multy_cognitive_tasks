{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two task network \n",
    "\n",
    "Network has eight inputs:\n",
    "\n",
    "1. The fixation. \n",
    "1. $u_{rule}^{1}$\n",
    "1. $u_{rule}^{2}$\n",
    "1. The first context mod. \n",
    "1. The second ontext mod. \n",
    "1. The first context status. \n",
    "1. The second context status. \n",
    "1. The Romo signals.\n",
    "\n",
    "Network has five outputs: \n",
    "1. The fixation. \n",
    "1. The first context output. \n",
    "1. The second context output. \n",
    "1. The first Romo task output. \n",
    "1. The second Romo task output. \n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"./images/Sheme.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "> Learning rule: superspike\n",
    "\n",
    "> Neuron type: Lif\n",
    "\n",
    "\n",
    "$$\\begin{align*}\n",
    "            \\dot{v} &= 1/\\tau_{\\text{mem}} (v_{\\text{leak}} - v + i) \\\\\n",
    "            \\dot{i} &= -1/\\tau_{\\text{syn}} i\n",
    "        \\end{align*}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt  # for analys\n",
    "from cgtasknet.net.lifrefrac import SNNLifRefrac\n",
    "from cgtasknet.tasks.tasks import MultyTask\n",
    "from norse.torch.functional.lif_refrac import LIFRefracParameters\n",
    "from norse.torch.functional.lif import LIFParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step -1: Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: gpu (cuda)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print(f'Device: {(\"gpu (cuda)\" if device.type==\"cuda\" else \"cpu\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "number_of_tasks = 10\n",
    "task_list = [(\"WorkingMemory\", dict()), ((\"ContextDM\", dict()))]\n",
    "tasks = dict(task_list)\n",
    "Task = MultyTask(tasks=tasks, batch_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size, output_size = Task.feature_and_act_size[0]\n",
    "hidden_size = 200\n",
    "\n",
    "neuron_parameters = LIFRefracParameters(LIFParameters())\n",
    "model = SNNLifRefrac(\n",
    "    feature_size, hidden_size, output_size, neuron_parameters=neuron_parameters\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Save pre-learning weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_pre_l = []\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            weights_pre_l.append((param).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: loss and creterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-2\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.8, 0.85))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "inputs += np.random.normal(0, 0.01, size=(inputs.shape))\n",
    "inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "epoch: 10 loss: 0.14129\n",
      "test loss: 0.12475\n",
      "22394\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.ion\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(111)\n",
    "inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "(line1,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line2,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "(line3,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line4,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "(line21,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line22,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "(line23,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line24,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "ax.set_ylim([-0.5, 1.5])\n",
    "ax.set_xlim([0, 20000])\n",
    "ax2.set_ylim([-0.5, 1.5])\n",
    "ax2.set_xlim([0, 20000])\n",
    "running_loss = 0\n",
    "fig.canvas.draw()\n",
    "fig.canvas.flush_events()\n",
    "fig2.canvas.draw()\n",
    "fig2.canvas.flush_events()\n",
    "ax.set_title(\"LIF\")\n",
    "ax2.set_title(\"LIF\")\n",
    "for i in range(2000):\n",
    "    inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "    inputs += np.random.normal(0, 0.01, size=(inputs.shape))\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs, states = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, target_outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 10 == 9:\n",
    "        print(\"epoch: {:d} loss: {:0.5f}\".format(i + 1, running_loss / 10))\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "            inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "            target_outputs = (\n",
    "                torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "            )\n",
    "            outputs, states = model(inputs)\n",
    "            loss = criterion(outputs, target_outputs)\n",
    "\n",
    "            print(\"test loss: {:0.5f}\".format(loss.item()))\n",
    "        for_plot = outputs.detach().cpu().numpy()[:, 0, :]\n",
    "        print(len(for_plot))\n",
    "        line1.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line2.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line3.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line4.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line21.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line22.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line23.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line24.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "\n",
    "        line1.set_ydata(for_plot[:, 1])\n",
    "        line2.set_ydata(for_plot[:, 2])\n",
    "        line3.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 1])\n",
    "        line4.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 2])\n",
    "\n",
    "        line21.set_ydata(for_plot[:, 3])\n",
    "        line22.set_ydata(for_plot[:, 4])\n",
    "        line23.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 3])\n",
    "        line24.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 4])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "    fig2.canvas.draw()\n",
    "    fig2.canvas.flush_events()\n",
    "\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f83ba25b4055e6850166001f95ed136092a6ce41bf7679ca537d862fe029930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
