{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two task network \n",
    "\n",
    "Network has eight inputs:\n",
    "\n",
    "1. The fixation. \n",
    "1. $u_{rule}^{1}$\n",
    "1. $u_{rule}^{2}$\n",
    "1. The first context mod. \n",
    "1. The second ontext mod. \n",
    "1. The first context status. \n",
    "1. The second context status. \n",
    "1. The Romo signals.\n",
    "\n",
    "Network has five outputs: \n",
    "1. The fixation. \n",
    "1. The first context output. \n",
    "1. The second context output. \n",
    "1. The first Romo task output. \n",
    "1. The second Romo task output. \n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"./images/Sheme.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "> Learning rule: superspike\n",
    "\n",
    "> Neuron type: Alif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt  # for analys\n",
    "from cgtasknet.net.lifadex import SNNlifadex\n",
    "from cgtasknet.tasks.tasks import MultyTask\n",
    "from norse.torch.functional.lif_adex import LIFAdExParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step -1: Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: gpu (cuda)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print(f'Device: {(\"gpu (cuda)\" if device.type==\"cuda\" else \"cpu\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "number_of_tasks = 8\n",
    "task_list = [(\"WorkingMemory\", dict()), ((\"ContextDM\", dict()))]\n",
    "tasks = dict(task_list)\n",
    "Task = MultyTask(tasks=tasks, batch_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size, output_size = Task.feature_and_act_size[0]\n",
    "hidden_size = 400\n",
    "\n",
    "neuron_parameters = LIFAdExParameters(\n",
    "    tau_ada_inv=torch.Tensor([2]).to(device), alpha=100\n",
    ")\n",
    "model = SNNlifadex(\n",
    "    feature_size, hidden_size, output_size, neuron_parameters=neuron_parameters\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Save pre-learning weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_pre_l = []\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            weights_pre_l.append((param).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: loss and creterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.8, 0.85))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.8, 0.85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "epoch: 10 loss: 0.30492\n",
      "test loss: 0.19008\n",
      "epoch: 20 loss: 0.17619\n",
      "test loss: 0.13627\n",
      "epoch: 30 loss: 0.10161\n",
      "test loss: 0.08640\n",
      "epoch: 40 loss: 0.07499\n",
      "test loss: 0.06266\n",
      "epoch: 50 loss: 0.06154\n",
      "test loss: 0.06476\n",
      "epoch: 60 loss: 0.05651\n",
      "test loss: 0.05464\n",
      "epoch: 70 loss: 0.05031\n",
      "test loss: 0.05663\n",
      "epoch: 80 loss: 0.04467\n",
      "test loss: 0.04865\n",
      "epoch: 90 loss: 0.04586\n",
      "test loss: 0.04491\n",
      "epoch: 100 loss: 0.04488\n",
      "test loss: 0.03907\n",
      "epoch: 110 loss: 0.04382\n",
      "test loss: 0.03687\n",
      "epoch: 120 loss: 0.04266\n",
      "test loss: 0.05720\n",
      "epoch: 130 loss: 0.03750\n",
      "test loss: 0.03064\n",
      "epoch: 140 loss: 0.04163\n",
      "test loss: 0.05733\n",
      "epoch: 150 loss: 0.04375\n",
      "test loss: 0.04293\n",
      "epoch: 160 loss: 0.03830\n",
      "test loss: 0.04011\n",
      "epoch: 170 loss: 0.03587\n",
      "test loss: 0.04793\n",
      "epoch: 180 loss: 0.03509\n",
      "test loss: 0.04754\n",
      "epoch: 190 loss: 0.03607\n",
      "test loss: 0.04524\n",
      "epoch: 200 loss: 0.03735\n",
      "test loss: 0.02073\n",
      "epoch: 210 loss: 0.03800\n",
      "test loss: 0.03129\n",
      "epoch: 220 loss: 0.03342\n",
      "test loss: 0.04841\n",
      "epoch: 230 loss: 0.03703\n",
      "test loss: 0.02346\n",
      "epoch: 240 loss: 0.03870\n",
      "test loss: 0.02058\n",
      "epoch: 250 loss: 0.03552\n",
      "test loss: 0.04098\n",
      "epoch: 260 loss: 0.03723\n",
      "test loss: 0.01984\n",
      "epoch: 270 loss: 0.03574\n",
      "test loss: 0.04542\n",
      "epoch: 280 loss: 0.03475\n",
      "test loss: 0.04509\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.ion\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig2 = plt.figure()\n",
    "\n",
    "ax2 = fig2.add_subplot(111)\n",
    "ax2.set_title(\"lifadex\")\n",
    "ax.set_title(\"lifadex\")\n",
    "inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "(line1,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line2,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "(line3,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line4,) = ax.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "(line21,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line22,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "(line23,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 1], \"b-\")\n",
    "(line24,) = ax2.plot(np.arange(0, len(target_outputs)), target_outputs[:, 0, 2], \"r-\")\n",
    "ax.set_ylim([-0.5, 1.5])\n",
    "ax.set_xlim([0, 20000])\n",
    "ax2.set_ylim([-0.5, 1.5])\n",
    "ax2.set_xlim([0, 20000])\n",
    "running_loss = 0\n",
    "fig.canvas.draw()\n",
    "fig.canvas.flush_events()\n",
    "fig2.canvas.draw()\n",
    "fig2.canvas.flush_events()\n",
    "for i in range(2000):\n",
    "    inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "    inputs += np.random.normal(0, 0.01, size=(inputs.shape))\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs, states = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, target_outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 10 == 9:\n",
    "        print(\"epoch: {:d} loss: {:0.5f}\".format(i + 1, running_loss / 10))\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "            inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "            target_outputs = (\n",
    "                torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "            )\n",
    "            outputs, states = model(inputs)\n",
    "            loss = criterion(outputs, target_outputs)\n",
    "\n",
    "            print(\"test loss: {:0.5f}\".format(loss.item()))\n",
    "        for_plot = outputs.detach().cpu().numpy()[:, 0, :]\n",
    "        line1.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line2.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line3.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line4.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line21.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line22.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line23.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "        line24.set_xdata(np.arange(0, len(for_plot), 1))\n",
    "\n",
    "        line1.set_ydata(for_plot[:, 1])\n",
    "        line2.set_ydata(for_plot[:, 2])\n",
    "        line3.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 1])\n",
    "        line4.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 2])\n",
    "\n",
    "        line21.set_ydata(for_plot[:, 3])\n",
    "        line22.set_ydata(for_plot[:, 4])\n",
    "        line23.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 3])\n",
    "        line24.set_ydata(target_outputs.detach().cpu().numpy()[:, 0, 4])\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n",
    "    fig2.canvas.draw()\n",
    "    fig2.canvas.flush_events()\n",
    "\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f83ba25b4055e6850166001f95ed136092a6ce41bf7679ca537d862fe029930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
